# åŒ»ç–—é—®ç­”æ¨¡å‹è®­ç»ƒå’Œè‡ªä¸»å­¦ä¹ ç³»ç»Ÿ

## æ¦‚è¿°

æœ¬ç³»ç»Ÿä¸ºæ‚¨çš„åŒ»ç–—é—®ç­”åº”ç”¨å¢åŠ äº†ä»¥ä¸‹åŠŸèƒ½ï¼š
1. **è‡ªä¸»è®­ç»ƒæ¨¡å‹** - åŸºäºTransformersçš„æ·±åº¦å­¦ä¹ é—®ç­”æ¨¡å‹
2. **è‡ªä¸»å­¦ä¹ æœºåˆ¶** - åŸºäºç”¨æˆ·åé¦ˆçš„æŒç»­æ”¹è¿›
3. **æ¨¡å‹è¯„ä¼°** - å…¨é¢çš„æ€§èƒ½è¯„ä¼°æŒ‡æ ‡
4. **è®­ç»ƒæ•°æ®ç®¡ç†** - æ™ºèƒ½æ•°æ®é¢„å¤„ç†å’Œç®¡ç†

## ç³»ç»Ÿæ¶æ„

```
åŒ»ç–—é—®ç­”ç³»ç»Ÿ
â”œâ”€â”€ åŸºç¡€é—®ç­”å¼•æ“ (api/models/medical_model.py)
â”œâ”€â”€ æ·±åº¦å­¦ä¹ è®­ç»ƒå™¨ (api/models/qa_trainer.py)
â”œâ”€â”€ æ•°æ®ç®¡ç†å™¨ (api/utils/training_data_manager.py)
â”œâ”€â”€ æ¨¡å‹è¯„ä¼°å™¨ (api/utils/model_evaluator.py)
â”œâ”€â”€ è‡ªä¸»å­¦ä¹ ç®¡ç†å™¨ (api/utils/auto_learning.py)
â”œâ”€â”€ è®­ç»ƒè„šæœ¬ (train.py)
â””â”€â”€ é…ç½®æ–‡ä»¶ (config/training_config.json)
```

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¤– è‡ªä¸»è®­ç»ƒæ¨¡å‹
- åŸºäºTransformersçš„ä¸­æ–‡åŒ»ç–—é—®ç­”æ¨¡å‹
- æ”¯æŒç”Ÿæˆå¼é—®ç­” (Seq2Seq)
- å¯é…ç½®çš„è®­ç»ƒå‚æ•°
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œå¤‡ä»½

### ğŸ“Š æ™ºèƒ½æ•°æ®å¤„ç†
- è‡ªåŠ¨ä»çŸ¥è¯†åº“ç”Ÿæˆé—®ç­”å¯¹ (182ä¸ªè®­ç»ƒæ ·æœ¬)
- æ”¯æŒç”¨æˆ·åé¦ˆæ•°æ®é›†æˆ
- æ•°æ®è´¨é‡æ£€æŸ¥å’Œå»é‡
- è®­ç»ƒ/éªŒè¯é›†è‡ªåŠ¨åˆ’åˆ†

### ğŸ”„ è‡ªä¸»å­¦ä¹ æœºåˆ¶
- åŸºäºç”¨æˆ·åé¦ˆçš„è‡ªåŠ¨é‡è®­ç»ƒ
- å¯é…ç½®çš„è§¦å‘æ¡ä»¶
- æ¨¡å‹æ€§èƒ½ç›‘æ§
- å¢é‡å­¦ä¹ æ”¯æŒ

### ğŸ“ˆ æ¨¡å‹è¯„ä¼°
- å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ (F1, BLEU, ROUGE, è¯­ä¹‰ç›¸ä¼¼åº¦)
- åŒ»ç–—å‡†ç¡®æ€§è¯„ä¼°
- æ‰¹é‡è¯„ä¼°å’ŒæŠ¥å‘Šç”Ÿæˆ
- æ€§èƒ½æ”¹è¿›è¿½è¸ª

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…æ·±åº¦å­¦ä¹ ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install torch==2.0.1 transformers==4.33.0 accelerate==0.21.0
```

### 2. åŸºç¡€åŠŸèƒ½æµ‹è¯•

```bash
# è¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_basic.py

# è¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆéœ€è¦æ·±åº¦å­¦ä¹ ä¾èµ–ï¼‰
python test_training.py
```

### 3. æ•°æ®å‡†å¤‡

```bash
# ç”Ÿæˆè®­ç»ƒæ•°æ®
python train.py prepare --include-feedback --output-dir api/data

# æŸ¥çœ‹æ•°æ®ç»Ÿè®¡
python train.py status
```

### 4. æ¨¡å‹è®­ç»ƒ

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python train.py train

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
python train.py train --config config/training_config.json --force

# ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
python train.py train --resume-from-checkpoint models/medical_qa/checkpoint-100
```

### 5. æ¨¡å‹è¯„ä¼°

```bash
# è¯„ä¼°è®­ç»ƒåçš„æ¨¡å‹
python train.py evaluate --model-path models/medical_qa

# ä½¿ç”¨è‡ªå®šä¹‰æµ‹è¯•æ•°æ®è¯„ä¼°
python train.py evaluate --test-file my_test_data.json --output-dir results
```

### 6. è‡ªä¸»å­¦ä¹ 

```bash
# å¯åŠ¨è‡ªä¸»å­¦ä¹ 
python train.py auto-learn

# å¼ºåˆ¶é‡è®­ç»ƒ
python train.py auto-learn --force-retrain

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
python train.py auto-learn --config config/training_config.json
```

## é…ç½®è¯´æ˜

### è®­ç»ƒé…ç½® (config/training_config.json)

```json
{
  "model_name": "hfl/chinese-bert-wwm-ext",  // é¢„è®­ç»ƒæ¨¡å‹
  "model_type": "seq2seq",                   // æ¨¡å‹ç±»å‹
  "max_length": 512,                         // æœ€å¤§è¾“å…¥é•¿åº¦
  "max_target_length": 128,                  // æœ€å¤§è¾“å‡ºé•¿åº¦
  "learning_rate": 2e-5,                     // å­¦ä¹ ç‡
  "batch_size": 4,                           // æ‰¹æ¬¡å¤§å°
  "num_epochs": 3,                           // è®­ç»ƒè½®æ•°
  "output_dir": "models/medical_qa"          // æ¨¡å‹ä¿å­˜è·¯å¾„
}
```

### è‡ªä¸»å­¦ä¹ é…ç½®

```json
{
  "auto_learning": {
    "min_feedback_count": 10,          // æœ€å°åé¦ˆæ•°é‡é˜ˆå€¼
    "min_low_score_ratio": 0.3,        // ä½åˆ†åé¦ˆæ¯”ä¾‹é˜ˆå€¼
    "feedback_score_threshold": 0.6,   // åé¦ˆè¯„åˆ†é˜ˆå€¼
    "retrain_interval_hours": 24,      // é‡è®­ç»ƒé—´éš”(å°æ—¶)
    "max_training_samples": 1000       // æœ€å¤§è®­ç»ƒæ ·æœ¬æ•°
  }
}
```

## API ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€é—®ç­” (ä¸éœ€è¦æ·±åº¦å­¦ä¹ ä¾èµ–)

```python
from api.models.medical_model import MedicalQAModel

# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = MedicalQAModel(use_deep_learning=False)

# ç”Ÿæˆç­”æ¡ˆ
result = model.generate_answer("æ„Ÿå†’æœ‰ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ")
print(result['answer'])
print(f"æ¥æº: {result['source']}")
print(f"ç½®ä¿¡åº¦: {result['confidence']}")
```

### æ·±åº¦å­¦ä¹ é—®ç­”

```python
from api.models.medical_model import MedicalQAModel

# åˆ›å»ºå¯ç”¨æ·±åº¦å­¦ä¹ çš„æ¨¡å‹
model = MedicalQAModel(use_deep_learning=True)

# ç”Ÿæˆç­”æ¡ˆ
result = model.generate_answer(
    question="é«˜è¡€å‹ç”¨ä»€ä¹ˆè¯æ²»ç–—ï¼Ÿ",
    context="æ‚£è€…è¯¢é—®è¯ç‰©æ²»ç–—",
    session_id="user_123"
)

print(result['answer'])
```

### æ·»åŠ ç”¨æˆ·åé¦ˆ

```python
# æ·»åŠ ç”¨æˆ·åé¦ˆç”¨äºè‡ªä¸»å­¦ä¹ 
model.add_feedback(
    question="æ„Ÿå†’ç—‡çŠ¶æ˜¯ä»€ä¹ˆï¼Ÿ",
    predicted_answer="æ„Ÿå†’æœ‰å‘çƒ­ç—‡çŠ¶",
    correct_answer="æ„Ÿå†’çš„ç—‡çŠ¶åŒ…æ‹¬å‘çƒ­ã€å’³å—½ã€æµé¼»æ¶•ã€å¤´ç—›ã€ä¹åŠ›ç­‰",
    score=0.6,
    feedback="ç­”æ¡ˆä¸å¤Ÿå®Œæ•´"
)
```

### æ¨¡å‹è®­ç»ƒ

```python
from api.models.qa_trainer import MedicalQATrainer, ModelConfig
from api.utils.training_data_manager import TrainingDataManager

# å‡†å¤‡è®­ç»ƒæ•°æ®
data_manager = TrainingDataManager('api/data')
train_data, val_data = data_manager.prepare_training_data()

# é…ç½®è®­ç»ƒå‚æ•°
config = ModelConfig(
    model_name="hfl/chinese-bert-wwm-ext",
    num_epochs=2,
    batch_size=4
)

# åˆ›å»ºè®­ç»ƒå™¨å¹¶è®­ç»ƒ
trainer = MedicalQATrainer(config)
trainer.train(train_data, val_data)
```

### æ¨¡å‹è¯„ä¼°

```python
from api.utils.model_evaluator import MedicalQAEvaluator

evaluator = MedicalQAEvaluator()

predictions = ["æ„Ÿå†’çš„ç—‡çŠ¶åŒ…æ‹¬å‘çƒ­ã€å’³å—½", "å»ºè®®å‰å¾€å†…ç§‘å°±è¯Š"]
references = ["æ„Ÿå†’ç—‡çŠ¶ï¼šå‘çƒ­ã€å’³å—½ã€æµé¼»æ¶•", "å»ºè®®æŒ‚å†…ç§‘å·"]

result = evaluator.evaluate_batch(predictions, references)
print(result['overall_metrics'])
```

## æ€§èƒ½æŒ‡æ ‡è¯´æ˜

- **F1 Score**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- **Exact Match**: å®Œå…¨åŒ¹é…ç‡
- **BLEU Score**: æœºå™¨ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡
- **ROUGE Score**: æ–‡æœ¬æ‘˜è¦è¯„ä¼°æŒ‡æ ‡
- **è¯­ä¹‰ç›¸ä¼¼åº¦**: åŸºäºåºåˆ—åŒ¹é…çš„ç›¸ä¼¼åº¦
- **åŒ»ç–—å‡†ç¡®æ€§**: åŒ»ç–—å®ä½“åŒ¹é…å‡†ç¡®æ€§

## æ•…éšœæ’é™¤

### 1. ä¾èµ–é—®é¢˜
```bash
# å¦‚æœtorchç‰ˆæœ¬å†²çª
pip uninstall torch transformers accelerate
pip install torch==2.0.1 transformers==4.33.0 accelerate==0.21.0
```

### 2. å†…å­˜ä¸è¶³
- å‡å°batch_size (å¦‚è®¾ä¸º2)
- å‡å°max_length (å¦‚è®¾ä¸º256)
- å‡å°‘è®­ç»ƒæ ·æœ¬æ•°

### 3. æ¨¡å‹åŠ è½½å¤±è´¥
- æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
- æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼‰

### 4. è®­ç»ƒæ•°æ®ä¸è¶³
```bash
# å¼ºåˆ¶è®­ç»ƒï¼ˆå³ä½¿æ•°æ®ä¸è¶³ï¼‰
python train.py train --force
```

## æ–‡ä»¶ç»“æ„

```
medical_app/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ data/                          # æ•°æ®æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ medical_data.json         # åŸºç¡€åŒ»ç–—æ•°æ®
â”‚   â”‚   â”œâ”€â”€ knowledge_graph.json      # çŸ¥è¯†å›¾è°±
â”‚   â”‚   â”œâ”€â”€ feedback_data.json        # ç”¨æˆ·åé¦ˆæ•°æ®
â”‚   â”‚   â”œâ”€â”€ train_data.json          # è®­ç»ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ val_data.json            # éªŒè¯æ•°æ®
â”‚   â”œâ”€â”€ models/                       # æ¨¡å‹æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ medical_model.py         # ä¸»è¦åŒ»ç–—æ¨¡å‹
â”‚   â”‚   â””â”€â”€ qa_trainer.py            # è®­ç»ƒå™¨
â”‚   â””â”€â”€ utils/                       # å·¥å…·æ¨¡å—
â”‚       â”œâ”€â”€ training_data_manager.py # æ•°æ®ç®¡ç†å™¨
â”‚       â”œâ”€â”€ model_evaluator.py       # æ¨¡å‹è¯„ä¼°å™¨
â”‚       â””â”€â”€ auto_learning.py         # è‡ªä¸»å­¦ä¹ ç®¡ç†å™¨
â”œâ”€â”€ models/                          # è®­ç»ƒåçš„æ¨¡å‹
â”‚   â””â”€â”€ medical_qa/                  # åŒ»ç–—é—®ç­”æ¨¡å‹
â”œâ”€â”€ config/                          # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ training_config.json         # è®­ç»ƒé…ç½®
â”œâ”€â”€ train.py                         # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_basic.py                    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ test_training.py                 # å®Œæ•´åŠŸèƒ½æµ‹è¯•
â””â”€â”€ requirements.txt                 # ä¾èµ–åˆ—è¡¨
```

## é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰æ¨¡å‹
å¯ä»¥é€šè¿‡ä¿®æ”¹`config/training_config.json`æ¥ä½¿ç”¨ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼š
- `hfl/chinese-bert-wwm-ext` (æ¨èï¼Œä¸­æ–‡ä¼˜åŒ–)
- `bert-base-chinese`
- `uer/chinese_roberta_L-12_H-768`

### 2. åˆ†å¸ƒå¼è®­ç»ƒ
å¯¹äºå¤§è§„æ¨¡æ•°æ®ï¼Œå¯ä»¥é…ç½®å¤šGPUè®­ç»ƒï¼š
```json
{
  "training_args": {
    "dataloader_num_workers": 4,
    "ddp_backend": "nccl"
  }
}
```

### 3. æ¨¡å‹é‡åŒ–
ä¸ºäº†å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ—¶é—´ï¼š
```json
{
  "deployment": {
    "model_optimization": {
      "use_quantization": true,
      "use_onnx": true
    }
  }
}
```

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªåŸé¡¹ç›®çš„è®¸å¯è¯æ¡æ¬¾ã€‚

## æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
1. æµ‹è¯•æ—¥å¿—: `test_basic.log`, `test_training.log`
2. è®­ç»ƒæ—¥å¿—: `training.log`
3. è¿è¡ŒåŸºç¡€æµ‹è¯•: `python test_basic.py`